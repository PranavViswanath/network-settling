<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Network Settling</title>
    <link rel="stylesheet" href="styles.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:wght@300;400;500&family=Inter:wght@300;400;500;600&display=swap" rel="stylesheet">
</head>
<body>
    <div class="app">
        <div class="attribution">
            <div>Made by Pranav Viswanath</div>
            <div>Intro to Cognitive Science @ GT</div>
            <div>Nov 2025</div>
        </div>
        
        <header>
            <h1>Network Settling</h1>
            <p>Watch a constraint satisfaction network solve a 4×4 Sudoku puzzle through parallel activation and inhibition</p>
        </header>

        <main>
            <div class="visualization">
                <div class="grid-section">
                    <div class="grid-wrapper">
                        <div id="grid" class="grid"></div>
                    </div>
                    <p class="hint">Click any cell to edit • Press Enter to confirm • Escape to cancel</p>
                </div>

                <div class="probability-panel">
                    <h3>Live Network Activity</h3>
                    <div id="networkStatus" class="network-status"></div>
                    <div id="probabilityViz" class="probability-viz">
                        <p class="placeholder">Click a cell to see its probability distribution update in real-time</p>
                    </div>
                </div>
            </div>

            <div class="controls">
                <button id="playPause" class="play-button">
                    <svg class="play-icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <polygon points="5 3 19 12 5 21 5 3"></polygon>
                    </svg>
                    <svg class="pause-icon hidden" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <rect x="6" y="4" width="4" height="16"></rect>
                        <rect x="14" y="4" width="4" height="16"></rect>
                    </svg>
                    <span class="button-text">Watch it settle</span>
                </button>

                <button id="step" class="icon-button" title="Step once">
                    <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <polygon points="5 4 15 12 5 20 5 4"></polygon>
                        <line x1="19" y1="5" x2="19" y2="19"></line>
                    </svg>
                </button>

                <button id="reset" class="icon-button" title="Reset">
                    <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <polyline points="1 4 1 10 7 10"></polyline>
                        <path d="M3.51 15a9 9 0 1 0 2.13-9.36L1 10"></path>
                    </svg>
                </button>

                <div class="stats">
                    <div class="stat">
                        <span class="stat-label">iteration</span>
                        <span id="iteration" class="stat-value">0</span>
                    </div>
                    <div class="stat">
                        <span class="stat-label">Δ max</span>
                        <span id="delta" class="stat-value">—</span>
                    </div>
                </div>
            </div>

            <div class="settings">
                <div class="setting">
                    <label for="speed">Speed</label>
                    <input type="range" id="speed" min="100" max="1000" value="500" step="50">
                    <span id="speedValue">500ms</span>
                </div>
                
                <div class="setting">
                    <label for="inhibition">Inhibition</label>
                    <input type="range" id="inhibition" min="0" max="100" value="50">
                    <span id="inhibitionValue">0.50</span>
                </div>
            </div>
        </main>

        <article class="writeup">
            <h2>Network Settling Visual Tool</h2>
            <p class="intro">This tool lets you input your own grid and watch how a network settles on the solution through competing activations, not traditional step-by-step logic. Change the cell values, press go, and see how different clues shape the solution and how quickly the network "relaxes" into the right state.</p>

            <section>
                <h3>What is This?</h3>
                <p>I'm trying to visualize constraint satisfaction using network settling, based on concepts from <a href="https://gatech.instructure.com/files/65969493/download?download_frd=1&verifier=fZP5Q1WLFB7dg6eI8Im4QvjRCOAqCzrZLnNxd8cw" target="_blank">Lecture 7 on Connections</a>. The idea is that concepts are represented as units and constraints as excitatory/inhibitory connections. We satisfy external constraints (what's known) by clamping those units. Then we spread activations from initialization and repeatedly update until stabilization - watching the network relax.</p>
                
                <p>For a 4×4 grid, each cell doesn't just hold one number. It has <em>four</em> activation levels representing the probability of being 1, 2, 3, or 4. So we're not just dealing with 16 cells - we're dealing with 64 units (16 cells x 4 possible values). Each cell takes its highest-probability value and broadcasts that to everyone in its row and column. If your value conflicts with mine, you send back an inhibitory signal saying "don't be this," and my probability for that value drops. If there's no conflict, probabilities stay or rise. All cells update in parallel until nothing changes.</p>
            </section>

            <section>
                <h3>Why I Built This</h3>
                <p>I was really excited about the generalizability of this approach after we talked about in lecture I wanted to find out whether you can really just set up a problem as a landscape of units and activations, add the right constraints, and let the answer emerge. There is no explicit algorithm or backtracking - just let the network figure it out.</p>
                
                <p>The hardest part was wrapping my head around the inhibition process. At first, I was thinking: if a value is impossible, does it go straight to probability 0? Or do probabilities just get lowered gradually? And how do we know the right solution will emerge if we're just doing local updates? Can we trust that the rules alone - inhibitory signals for conflicts and clamped inputs for clues - will organize the whole grid into a valid solution?</p>
                
                <p>Turns out, yes! You initialize unknown cells at 25% for each value (totally uncertain), clamp the known values at 100%, then iterate: argmax each cell's probabilities to get its current "vote", send that to everyone in the same row or column, receive inhibitory signals back if there's a conflict, update probabilities, and repeat until no cell changes. The solution just emerges!</p>
            </section>

            <section>
                <h3>The Math (How It Actually Works)</h3>
                <p>What's happening under the hood? For a 4×4 grid, we're not just tracking 16 cells - we're tracking 64 units (16 cells × 4 possible values). Each unit has a probability p<sub>r,c,v</sub> where r is the row, c is the column, and v is the value. The probabilities for each cell sum to 1.</p>
                
                <p>The update rule each iteration is pretty straightforward. For each cell and each possible value:</p>
                
                <p><strong>First, hard constraints:</strong> If a value is already clamped (set as a clue) in the same row or column, that value's probability goes straight to 0. It's impossible, so we rule it out immediately.</p>
                
                <p><strong>Second, soft constraints (the inhibition):</strong> For values that aren't impossible, we calculate how much "competition" they face. We look at all the other cells in the same row and column, check how much each of them wants this same value, and average that. That's the inhibition signal. Then we update: p<sub>new</sub> = p<sub>old</sub> × (1 - α × inhibition), where α is the inhibition strength (default 0.5, adjustable with the slider). Higher inhibition means the probability drops more.</p>
                
                <p><strong>Finally, normalize:</strong> After applying inhibition, we rescale all the probabilities for that cell so they sum back to 1. This keeps everything as a proper probability distribution.</p>
                
                <p>The key insight is that all cells update in parallel. When Cell A lowers its probability for value 3 because Cell B wants it, that change immediately affects Cell B's next update. It's a feedback loop - everyone's sending signals to everyone else, and the whole system settles into a state where all the constraints are satisfied. No cell is "in charge" - the solution emerges from all these local interactions happening at once.</p>
                
                <p>We stop when the maximum change across all probabilities drops below 0.001. At that point, the network has converged - every cell has basically decided on a value, and no one's changing their mind anymore.</p>
            </section>

            <section>
                <h3>Why This Matters (CogSci Perspective)</h3>
                <p>This is <strong>connectionism</strong> in action. Instead of symbolic AI, where you explicitly program rules and logic, you represent knowledge as activation patterns across units and constraints as weighted connections. The answer is not computed step by step. It self-organizes from local interactions. This is how neural networks work and possibly how the brain might solve problems: parallel processing, competition, and constraint satisfaction through spreading activation.</p>
                
                <p>What I find cool is that you can literally <em>watch</em> information propagate. A single clamped clue sends ripples through the network. Probabilities shift, conflicts resolve, and gradually the whole grid converges. It's emergent behavior from simple rules - that is the whole point of connectionist models.</p>
            </section>

            <section>
                <h3>What's Next</h3>
                <p>This is a first pass, in the future I'd love to add more visual feedback, such as showing inhibitory connections as they fire. I also want to support bigger grids or let users design custom constraints beyond Sudoku rules. If you're interested in how cognitive science theories become actual working code - or you just want to see parallel constraint satisfaction happen live - feel free to play around and experiment.</p>
                
                <p>The original lecture that inspired this is <a href="https://gatech.instructure.com/files/65969493/download?download_frd=1&verifier=fZP5Q1WLFB7dg6eI8Im4QvjRCOAqCzrZLnNxd8cw" target="_blank">here</a>.</p>
            </section>
        </article>

        <footer>
            <p>Built with Python (via Pyodide) | Georgia Tech CS | November 2025</p>
        </footer>
    </div>

    <script src="https://cdn.jsdelivr.net/pyodide/v0.25.1/full/pyodide.js"></script>
    <script src="app.js"></script>
</body>
</html>
